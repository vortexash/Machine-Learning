{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Latent_Dirichlet_Allocation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vortexash/Machine-Learning/blob/master/Latent_Dirichlet_Allocation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFjvJijW0IA5",
        "colab_type": "text"
      },
      "source": [
        "##loading the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9ZHs7-u0RtV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpj29Ev60U85",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url='https://raw.githubusercontent.com/udacity/NLP-Exercises/master/2.2-topic-modeling/abcnews-date-text.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K9bS9od0XMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=pd.read_csv(url,error_bad_lines=False)\n",
        "data_text=data[:300000][['headline_text']]\n",
        "data_text['index'] = data_text.index\n",
        "documents =data_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGiZZx8X0nKf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a998fd10-61de-4edc-c262-79fe187d2aba"
      },
      "source": [
        "documents.head(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       headline_text  index\n",
              "0  aba decides against community broadcasting lic...      0\n",
              "1     act fire witnesses must be aware of defamation      1\n",
              "2     a g calls for infrastructure protection summit      2\n",
              "3           air nz staff in aust strike for pay rise      3\n",
              "4      air nz strike to affect australian travellers      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImUZ6yxm1lKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6237fa14-c222-4a78-efee-becdecaaf1fd"
      },
      "source": [
        "##total number of documents\n",
        "print(len(documents))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "300000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c73_hqsF1vTU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "17af3dff-b938-4641-d8cf-1793a91fb898"
      },
      "source": [
        "documents[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       headline_text  index\n",
              "0  aba decides against community broadcasting lic...      0\n",
              "1     act fire witnesses must be aware of defamation      1\n",
              "2     a g calls for infrastructure protection summit      2\n",
              "3           air nz staff in aust strike for pay rise      3\n",
              "4      air nz strike to affect australian travellers      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U4UpG5K1_eV",
        "colab_type": "text"
      },
      "source": [
        "#Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABtyvImN4p_o",
        "colab_type": "text"
      },
      "source": [
        "1. **Tokenization**: Split the text into sentences and the sentences into words. Lowercase the words and remove punctuation.\n",
        "\n",
        "2. Words that have fewer than 3 characters are removed.\n",
        "\n",
        "3. All **stopwords** are removed.\n",
        "Words are **lemmatized** - words in third person are changed to first person and verbs in past and future tenses are changed into present.\n",
        "\n",
        "3. Words are **stemmed** - words are reduced to their root form.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8N1QO0c2Bbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Loading Gensim and nltk libraries\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "np.random.seed(400)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhiFTcpH5-nX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "123fc037-7a68-408e-dbc9-eb77b5d21206"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3SGLfSK7KAj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51aa72a2-7f9c-4bf6-82c3-bff19bb52afb"
      },
      "source": [
        "### Practice Lemmatizer Example\n",
        " print(WordNetLemmatizer().lemmatize('went',pos = 'v')) ## past tence to present tense"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "go\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi3oc6-K73ys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "310fb8b1-0b0c-4507-8fbf-276b6a81ba07"
      },
      "source": [
        "#### Stemmer Example\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
        "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
        "           'traditional', 'reference', 'colonizer','plotted'] \n",
        "singles = [stemmer.stem(plural) for plural in original_words]\n",
        "pd.DataFrame(data={'original_words':original_words,'Stemmed':singles})"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>original_words</th>\n",
              "      <th>Stemmed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>caresses</td>\n",
              "      <td>caress</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>flies</td>\n",
              "      <td>fli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dies</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mules</td>\n",
              "      <td>mule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>denied</td>\n",
              "      <td>deni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>died</td>\n",
              "      <td>die</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>agreed</td>\n",
              "      <td>agre</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>owned</td>\n",
              "      <td>own</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>humbled</td>\n",
              "      <td>humbl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sized</td>\n",
              "      <td>size</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>meeting</td>\n",
              "      <td>meet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>stating</td>\n",
              "      <td>state</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>siezing</td>\n",
              "      <td>siez</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>itemization</td>\n",
              "      <td>item</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>sensational</td>\n",
              "      <td>sensat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>traditional</td>\n",
              "      <td>tradit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>reference</td>\n",
              "      <td>refer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>colonizer</td>\n",
              "      <td>colon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>plotted</td>\n",
              "      <td>plot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   original_words Stemmed\n",
              "0        caresses  caress\n",
              "1           flies     fli\n",
              "2            dies     die\n",
              "3           mules    mule\n",
              "4          denied    deni\n",
              "5            died     die\n",
              "6          agreed    agre\n",
              "7           owned     own\n",
              "8         humbled   humbl\n",
              "9           sized    size\n",
              "10        meeting    meet\n",
              "11        stating   state\n",
              "12        siezing    siez\n",
              "13    itemization    item\n",
              "14    sensational  sensat\n",
              "15    traditional  tradit\n",
              "16      reference   refer\n",
              "17      colonizer   colon\n",
              "18        plotted    plot"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSGra48-8tZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## now on the entire dataset\n",
        " def lemmantize_stemming(text):\n",
        "    return(stemmer.stem(WordNetLemmatizer().lemmatize(text,pos='v')))\n",
        "## Tokenize and lemmatize\n",
        "def preprocess(text):\n",
        "  result=[]\n",
        "  for token in gensim.utils.simple_preprocess(text):\n",
        "    if token not in gensim.parsing.preprocessing.STOPWORDS and len(token)>3:\n",
        "      result.append(lemmantize_stemming(token))\n",
        "  return(result)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjtblb-uAqO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "0e9c379a-9861-40c8-f947-c6aca1d1f86c"
      },
      "source": [
        " ## preview a document after preprocessing \n",
        "document_num = 4310\n",
        "doc_sample = documents[documents['index']==document_num].values[0][0]\n",
        "print(\"Original Document:\")\n",
        "words=[]\n",
        "for word in doc_sample.split(' '):\n",
        "  words.append(word)\n",
        "print(words)\n",
        "print(\"\\n\\nTokenized and lemmatized document:\")\n",
        "print(preprocess(doc_sample))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Document:\n",
            "['rain', 'helps', 'dampen', 'bushfires']\n",
            "\n",
            "\n",
            "Tokenized and lemmatized document:\n",
            "['rain', 'help', 'dampen', 'bushfir']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMSEvr-WCcfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Now use map function from pandas to apply preprocessing() to the headline_text\n",
        "\n",
        "processed_docs=documents['headline_text'].map(preprocess)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCosYJbuDggY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ce35b403-7b92-4eab-b8c0-e884b2102cb3"
      },
      "source": [
        "processed_docs[:10]"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0            [decid, communiti, broadcast, licenc]\n",
              "1                               [wit, awar, defam]\n",
              "2           [call, infrastructur, protect, summit]\n",
              "3                      [staff, aust, strike, rise]\n",
              "4             [strike, affect, australian, travel]\n",
              "5               [ambiti, olsson, win, tripl, jump]\n",
              "6           [antic, delight, record, break, barca]\n",
              "7    [aussi, qualifi, stosur, wast, memphi, match]\n",
              "8            [aust, address, secur, council, iraq]\n",
              "9                         [australia, lock, timet]\n",
              "Name: headline_text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMzamRVUETCu",
        "colab_type": "text"
      },
      "source": [
        "#Bag of word on the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLNlHq0sEKUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = gensim.corpora.Dictionary(processed_docs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od_jFyaEEk12",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "36333ce4-e5bc-4a48-e7f7-44930791bf86"
      },
      "source": [
        "## checking dictionary created\n",
        "count = 0\n",
        "for k, v in dictionary.iteritems():\n",
        "  print(k,v)\n",
        "  count+=1\n",
        "  if(count>10):\n",
        "    break"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 broadcast\n",
            "1 communiti\n",
            "2 decid\n",
            "3 licenc\n",
            "4 awar\n",
            "5 defam\n",
            "6 wit\n",
            "7 call\n",
            "8 infrastructur\n",
            "9 protect\n",
            "10 summit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8MMk-xZFLHo",
        "colab_type": "text"
      },
      "source": [
        "**Gensim filter_extremes**\n",
        "filter_extremes(no_below=5, no_above=0.5, keep_n=100000)\n",
        "\n",
        "Filter out tokens that appear in\n",
        "\n",
        "1. less than no_below documents (absolute number) or\n",
        "\n",
        "2. more than no_above documents (fraction of total corpus size, not absolute number).\n",
        "\n",
        "3. after (1) and (2), keep only the first keep_n most frequent tokens (or keep all if None)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoTk-t97E-XU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary.filter_extremes(no_below=15, no_above=0.1, keep_n=100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bu1Vn6dFlTy",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "###Gensim doc2bow\n",
        "doc2bow(document):\n",
        "\n",
        "1. Convert document (a list of words) into the bag-of-words format = list of (token_id, token_count) 2-tuples. Each word is assumed to be a tokenized and normalized string (either unicode or utf8-encoded). No further preprocessing is done on the words in document; apply tokenization, stemming etc. before calling this method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYfZ9J3fFjKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRunof80GOKA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9a50a33-90a9-4eda-cd65-ba66e1a1dff2"
      },
      "source": [
        "bow_corpus[document_num]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(71, 1), (107, 1), (462, 1), (3530, 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjTYbUNxGUgD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "45aed04d-51e0-471f-f9e2-6674e1e460b1"
      },
      "source": [
        "## Bow for our sample preprocessed document\n",
        "\n",
        "bow_doc_4310 = bow_corpus[document_num]\n",
        "for i in range(len(bow_doc_4310)):\n",
        "  print(\"Word {} (\\\"{}\\\") appears {} time.\" .format(bow_doc_4310[i][0],\n",
        "        dictionary[bow_doc_4310[i][0]],bow_doc_4310[i][1]))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word 71 (\"bushfir\") appears 1 time.\n",
            "Word 107 (\"help\") appears 1 time.\n",
            "Word 462 (\"rain\") appears 1 time.\n",
            "Word 3530 (\"dampen\") appears 1 time.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJLUEtwdHajn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}